{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(arr, n):\n",
    "    avg = len(arr) // n\n",
    "    remainder = len(arr) % n\n",
    "    result = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if i < remainder:\n",
    "            end = start + avg + 1\n",
    "        else:\n",
    "            end = start + avg\n",
    "        result.append(arr[start:end])\n",
    "        start = end\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_data(n):\n",
    "    data= pd.read_csv(\"mail.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    trainloaders=[]\n",
    "    testloaders = []\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = data['Message']\n",
    "    y = data['real']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase=True)\n",
    "    X_train = feature_extraction.fit_transform(X_train)\n",
    "\n",
    "    X_test = feature_extraction.transform(X_test)\n",
    "\n",
    "    X_train=X_train.toarray()\n",
    "    X_test=X_test.toarray()\n",
    "\n",
    "\n",
    "\n",
    "    X_train=split_array(X_train, n)\n",
    " \n",
    "    y_train=split_array(y_train, n)\n",
    "\n",
    "\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test= torch.Tensor(y_test.values)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "    X_test=X_test.to(device)\n",
    "    y_test=y_test.to(device)\n",
    "    X_test_hold=X_test\n",
    "    y_test_hold=y_test\n",
    "    testloaders=[]\n",
    "    testloaders.append((X_test,y_test))\n",
    "    for i in range(n):\n",
    "        X_train[i] = torch.Tensor(X_train[i])\n",
    "        y_train[i] = torch.Tensor(y_train[i].values)\n",
    "        X_train[i] = torch.tensor(X_train[i], dtype=torch.float32)\n",
    "        y_train[i] = torch.tensor(y_train[i], dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        X_train[i]=X_train[i].to(device)\n",
    "        y_train[i]=y_train[i].to(device)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        hold1=[]\n",
    "        hold2=[]\n",
    "        hold1.append((X_train[i],y_train[i]))\n",
    "        trainloaders.append(hold1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_testloader = [item for sublist in testloaders for item in sublist]\n",
    "\n",
    "    return trainloaders,combined_testloader,X_test_hold,y_test_hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden2 = nn.Linear(100, 200)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        self.hidden3 = nn.Linear(200, 50)\n",
    "        self.output= nn.Linear(50, 1)\n",
    "\n",
    "        self.act_output = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        #x = self.act2(self.input_layer(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act2(self.hidden3(x))\n",
    "        #x = self.act_output(self.output(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ModelB, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(1894, 100)\n",
    "        self.act1 = nn.Sigmoid() \n",
    "        self.model = model# Insert Model A in between input and output\n",
    "        \n",
    "        self.output= nn.Linear(50, 1)\n",
    "\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.input_layer(x))\n",
    "        x = self.model(x)  # Pass through Model A\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    def give(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,n_epochs,batch_size,traindata,lr):\n",
    "    X_train=traindata[0][0]\n",
    "    model=model.to(device)\n",
    "    y_train=traindata[0][1]\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    for epoch in range(n_epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                Xbatch = X_train[i:i+batch_size]\n",
    "                y_pred = model(Xbatch)\n",
    "                ybatch = y_train[i:i+batch_size]\n",
    "                loss = loss_func(y_pred, ybatch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "\n",
    "            if epoch % 500 == 0 & epoch != 0:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(X_train)\n",
    "\n",
    "                accuracy = (y_pred.round() == y_train).float().mean()\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(X_train)\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Accuracy {accuracy}\")\n",
    "                print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "\n",
    "\n",
    "def test(model, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    model=model.to(device)\n",
    "    X_test=testloader[0][0]\n",
    "    \n",
    "    y_test=testloader[0][1]\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    loss_func = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "    accuracy = (y_pred.round() == y_test).float().mean()\n",
    "\n",
    "    loss = loss_func(y_pred, y_test)\n",
    "\n",
    "    return loss.tolist(), accuracy.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "def test_whole_data(model, x,y):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    model=model.to(device)\n",
    "    X_test=x\n",
    "    y_test=y\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    loss_func = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "    accuracy = (y_pred.round() == y_test).float().mean()\n",
    "\n",
    "    loss = loss_func(y_pred, y_test)\n",
    "\n",
    "    return loss.tolist(), accuracy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_model(n):\n",
    "    model_list=[]\n",
    "    for i in range(n):\n",
    "        model1=ModelA()\n",
    "\n",
    "\n",
    "        model2=ModelB(model1)\n",
    "     \n",
    "        model_list.append(model2)\n",
    "    return model_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_standard(n,k,n_epochs,batch_size):\n",
    "\n",
    "    trainloaders,testloaders,x_test,y_test=creat_data(n)\n",
    "    \n",
    "\n",
    "    mod_list=num_model(n)\n",
    "    \n",
    "\n",
    "    max_value=0\n",
    "\n",
    "    acc=[]\n",
    "    epo=[]\n",
    "    curr=0\n",
    "    for i in range(k):\n",
    "\n",
    "        for z in range(n):\n",
    "            train(mod_list[z],n_epochs,batch_size,trainloaders[z],lr=0.001)\n",
    "\n",
    "        epo.append(curr)\n",
    "        curr=curr+1\n",
    "        print(curr)\n",
    "\n",
    "        res_acc=[]  \n",
    "        res_loss=[]        \n",
    "        for i in range(n):\n",
    "            hold=test_whole_data(mod_list[i],x_test,y_test)\n",
    "            print(hold)\n",
    "            res_acc.append(hold[1])\n",
    "            res_loss.append(hold[0])\n",
    "\n",
    "\n",
    "        avg_value=sum(res_acc)/n\n",
    "        avg_loss=sum(res_loss)/n\n",
    "        print(f'avrage value {avg_value}')\n",
    "\n",
    "        acc.append([avg_value,avg_loss])  \n",
    "        if avg_value > max_value:\n",
    "             max_value=avg_value\n",
    "\n",
    "\n",
    "        parameter_lists=[]\n",
    "        for model in mod_list:\n",
    "            hold=model.give()\n",
    "            parameter_lists.append(hold.parameters())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        avg_params = [torch.mean(torch.stack(params), dim=0) for params in zip(*parameter_lists)]\n",
    "\n",
    "        \n",
    "\n",
    "        glob_hold = ModelA() \n",
    "\n",
    "        \n",
    "        updated_params = []\n",
    "\n",
    "        \n",
    "        for glob_param, avg_param in zip(glob_hold.parameters(), avg_params):\n",
    "            updated_params.append(avg_param)\n",
    "\n",
    "       \n",
    "        for glob_param, updated_param in zip(glob_hold.parameters(), updated_params):\n",
    "            glob_param.data.copy_(updated_param)\n",
    "\n",
    "        for model_instance in mod_list:\n",
    "                model_instance.model = glob_hold\n",
    "\n",
    "\n",
    "    \n",
    "    plt.plot(epo,acc,label=('Average Accuracy',\"Average Loss\"))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Convergence of Federated Learning with 15 Models (5 Epochs, Batch Size 32)\")\n",
    "    plt.legend()\n",
    "    plt.axes([1, 0.4, 0.2, 0.2])\n",
    "    plt.boxplot(res_acc)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title('Boxplot of Accuracy')\n",
    "    plt.show()\n",
    "    return max_value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_global_standard(15,500,5,32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_imp(n,k,n_epochs,batch_size):\n",
    "\n",
    "    trainloaders,testloaders,x_test,y_test=creat_data(n)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    mod_list=num_model(n)\n",
    "    for i in range(n):\n",
    "        train(mod_list[i],1000,batch_size,trainloaders[i],lr=0.001)\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    acc=[]\n",
    "    epo=[]\n",
    "    curr=0\n",
    "    for i in range(k):\n",
    "\n",
    "        for i in range(n):\n",
    "            train(mod_list[i],n_epochs,batch_size,trainloaders[i],lr=0.002)\n",
    "\n",
    "        epo.append(curr)\n",
    "        curr=curr+1\n",
    "        print(curr)\n",
    "\n",
    "        res_acc=[]  \n",
    "        res_loss=[]        \n",
    "        for i in range(n):\n",
    "            hold=test_whole_data(mod_list[i],x_test,y_test)\n",
    "            print(hold)\n",
    "            res_acc.append(hold[1])\n",
    "            res_loss.append(hold[0])\n",
    "\n",
    "\n",
    "        avg_value=sum(res_acc)/n\n",
    "        avg_loss=sum(res_loss)/n\n",
    "        print(f'avrage value {avg_value}')\n",
    "\n",
    "        acc.append([avg_value,avg_loss])    \n",
    "\n",
    "\n",
    "        parameter_lists=[]\n",
    "        k=0\n",
    "        for model in mod_list:\n",
    "            if res_acc[k]>0:\n",
    "                print(\"fedder\")\n",
    "                hold=model.give()\n",
    "                parameter_lists.append(hold.parameters())\n",
    "            k=k+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        avg_params = [torch.mean(torch.stack(params), dim=0) for params in zip(*parameter_lists)]\n",
    "\n",
    "        \n",
    "\n",
    "        glob_hold = ModelA() \n",
    "\n",
    "        \n",
    "        updated_params = []\n",
    "\n",
    "        \n",
    "        for glob_param, avg_param in zip(glob_hold.parameters(), avg_params):\n",
    "            updated_params.append(avg_param)\n",
    "\n",
    "       \n",
    "        for glob_param, updated_param in zip(glob_hold.parameters(), updated_params):\n",
    "            glob_param.data.copy_(updated_param)\n",
    "\n",
    "        # Freeze all layers in glob_hold\n",
    "        if curr % 32 == 0:\n",
    "            print(\"fixer\")\n",
    "            \n",
    "            for param in glob_hold.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "\n",
    "            for model_instance in mod_list:\n",
    "                model_instance.model = glob_hold\n",
    "                \n",
    "\n",
    "      \n",
    "            k=0\n",
    "            for i in range(n):\n",
    "                if res_acc[k]<avg_value:\n",
    "                    print(\"fed_fix\")\n",
    "                    train(mod_list[i],n_epochs+50,batch_size,trainloaders[i],lr=0.0035)\n",
    "                k=k+1\n",
    "\n",
    "            for model_instance in mod_list:\n",
    "                    for param in model_instance.parameters():\n",
    "                        param.requires_grad = True\n",
    "        else:\n",
    "            for model_instance in mod_list:\n",
    "                model_instance.model = glob_hold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "         \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(epo,acc,label=('Average Accuracy',\"Average Loss\"))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Convergence of Federated Learning with 15 Models (5 Epochs, Batch Size 32)\")\n",
    "    plt.legend()\n",
    "    plt.axes([1, 0.4, 0.2, 0.2])\n",
    "    plt.boxplot(res_acc)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title('Boxplot of Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_global_imp(15,300,5,32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(1894, 100)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.hidden2 = nn.Linear(100, 200)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        self.hidden3 = nn.Linear(200, 50)\n",
    "        self.output= nn.Linear(50, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act2(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_model(n):\n",
    "    model_list=[]\n",
    "    for i in range(n):\n",
    "        model_list.append(Model())\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_data(n):\n",
    "    data= pd.read_csv(\"mail.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    trainloaders=[]\n",
    "    testloaders = []\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = data['Message']\n",
    "    y = data['real']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase=True)\n",
    "    X_train = feature_extraction.fit_transform(X_train)\n",
    "\n",
    "    X_test = feature_extraction.transform(X_test)\n",
    "\n",
    "    X_train=X_train.toarray()\n",
    "    X_test=X_test.toarray()\n",
    "\n",
    "\n",
    "\n",
    "    X_train=split_array(X_train, n)\n",
    " \n",
    "    y_train=split_array(y_train, n)\n",
    "\n",
    "\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test= torch.Tensor(y_test.values)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "    X_test=X_test.to(device)\n",
    "    y_test=y_test.to(device)\n",
    "    X_test_hold=X_test\n",
    "    y_test_hold=y_test\n",
    "    testloaders=[]\n",
    "    testloaders.append((X_test,y_test))\n",
    "    for i in range(n):\n",
    "        X_train[i] = torch.Tensor(X_train[i])\n",
    "        y_train[i] = torch.Tensor(y_train[i].values)\n",
    "        X_train[i] = torch.tensor(X_train[i], dtype=torch.float32)\n",
    "        y_train[i] = torch.tensor(y_train[i], dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        X_train[i]=X_train[i].to(device)\n",
    "        y_train[i]=y_train[i].to(device)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        hold1=[]\n",
    "        hold2=[]\n",
    "        hold1.append((X_train[i],y_train[i]))\n",
    "        trainloaders.append(hold1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_testloader = [item for sublist in testloaders for item in sublist]\n",
    "\n",
    "    return trainloaders,combined_testloader,X_test_hold,y_test_hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global(n,k,n_epochs,batch_size):\n",
    "\n",
    "    mod_list=num_model(n)\n",
    "    trainloaders,testloaders,x_test,y_test=creat_data(n)\n",
    "\n",
    "\n",
    "    glob_model=Model()\n",
    "    acc=[]\n",
    "    epo=[]\n",
    "    curr=0\n",
    "    for i in range(k):\n",
    "\n",
    "        for i in range(n):\n",
    "            train(mod_list[i],n_epochs,batch_size,trainloaders[i],0.001)\n",
    "\n",
    "        epo.append(curr)\n",
    "        curr=curr+1\n",
    "        print(curr)\n",
    "\n",
    "        res_acc=[]  \n",
    "        res_loss=[]        \n",
    "        for i in range(n):\n",
    "            hold=test_whole_data(mod_list[i],x_test,y_test)\n",
    "            print(hold)\n",
    "            res_acc.append(hold[1])\n",
    "            res_loss.append(hold[0])\n",
    "\n",
    "\n",
    "        avg_value=sum(res_acc)/n\n",
    "        avg_loss=sum(res_loss)/n\n",
    "        print(f'avrage value {avg_value}')\n",
    "\n",
    "        acc.append([avg_value,avg_loss])   \n",
    "\n",
    "        parameter_lists = [model.parameters() for model in mod_list]\n",
    "\n",
    "        avg_params = [torch.mean(torch.stack(params), dim=0) for params in zip(*parameter_lists)]\n",
    "\n",
    "        for glob_param, param in zip(glob_model.parameters(), avg_params):\n",
    "            glob_param.data.copy_(param)\n",
    "\n",
    "        mod_list=[]\n",
    "\n",
    "        for i in range(n):\n",
    "            mod_list.append(glob_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(epo,acc,label=('Average Accuracy',\"Average Loss\"))\n",
    "\n",
    "    \n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Convergence of Federated Learning with 15 Models (5 Epochs, Batch Size 32)\")\n",
    "    plt.legend()\n",
    "    plt.axes([1, 0.4, 0.2, 0.2])\n",
    "    plt.boxplot(res_acc)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title('Boxplot of Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_global(15,100,5,32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FedAvg",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
